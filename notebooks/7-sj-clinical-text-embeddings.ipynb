{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical terms were generated and categorized by ChatGPTv3 (6-4-2023)\n",
    "medical_terms = {\n",
    "    'brain_tumours': [\"Basal ganglia\", \"Brainstem\", \"Cerebellum\", \"Diencephalon\", \"Epithalamus\", \"Frontal lobe\", \"Gyrus\", \"Hippocampus\", \"Insula\", \"Junction\", \"Kuhne's commissure\", \"Limbic lobe\", \"Midbrain\", \"Nucleus\", \"Occipital lobe\", \"Parietal lobe\", \"Quadrigeminal plate\", \"Reticular formation\", \"Sulcus\", \"Temporal lobe\", \"Uncus\", \"lateral ventricle\", \"third ventricle\", \"fourth ventricle\", \"White matter\", \"Corpus callosum\", \"Pineal gland\", \"Pons\"],\n",
    "    'Cardiology': ['Arrhythmia', 'Atherosclerosis', 'Cardiomyopathy', 'Endocarditis', 'Myocardial infarction', 'Pericarditis', 'Tachycardia'],\n",
    "    'Dermatology': ['Acne', 'Dermatitis', 'Eczema', 'Hives', 'Melanoma', 'Psoriasis', 'Rosacea'],\n",
    "    'Endocrinology': ['Diabetes mellitus', 'Goiter', 'Hyperthyroidism', 'Hypothyroidism', 'Osteoporosis', 'Pheochromocytoma', 'Pituitary adenoma'],\n",
    "    'Gastroenterology': ['Cholecystitis', 'Cirrhosis', 'Colitis', 'Gastroenteritis', 'Hepatitis', 'Pancreatitis', 'Ulcerative colitis'],\n",
    "    'Hematology': ['Anemia', 'Hemophilia', 'Leukemia', 'Lymphoma', 'Multiple myeloma', 'Sickle cell anemia', 'Thrombocytopenia'],\n",
    "    'Neurology': ['Alzheimer\\'s disease', 'Epilepsy', 'Meningitis', 'Multiple sclerosis', 'Parkinson\\'s disease', 'Stroke', 'Traumatic brain injury'],\n",
    "    'Oncology': ['Carcinoma', 'Chemotherapy', 'Immunotherapy', 'Metastasis', 'Radiation therapy', 'Sarcoma', 'Tumor'],\n",
    "}\n",
    "\n",
    "all_terms = []\n",
    "for key, item in medical_terms.items():\n",
    "    all_terms.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(all_terms, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took 55.719733s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "with torch.no_grad():\n",
    "    for _ in range(20):\n",
    "        outputs = model(**inputs)\n",
    "print(f\"This took {time() - start:2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([77, 10, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states.shape # examples, max number of tokens in sequence, hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select useful features from the output\n",
    "features_cls = last_hidden_states[:, 0, :] # [CLS] embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 7 nearest neighbors...\n",
      "[t-SNE] Indexed 77 samples in 0.095s...\n",
      "[t-SNE] Computed neighbors for 77 samples in 0.015s...\n",
      "[t-SNE] Computed conditional probabilities for sample 77 / 77\n",
      "[t-SNE] Mean sigma: 0.661291\n",
      "[t-SNE] Computed conditional probabilities in 0.002s\n",
      "[t-SNE] Iteration 50: error = 76.6415405, gradient norm = 0.5136506 (50 iterations in 55.580s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pca_tranformed_features_cls \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mfit_transform(features_cls)\n\u001b[1;32m      3\u001b[0m tsne \u001b[39m=\u001b[39m TSNE(perplexity\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m transformed_features_cls \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39;49mfit_transform(pca_tranformed_features_cls)\n",
      "File \u001b[0;32m~/.conda/envs/pmchhg/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1119\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[0;32m-> 1119\u001b[0m embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m   1120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_ \u001b[39m=\u001b[39m embedding\n\u001b[1;32m   1121\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_\n",
      "File \u001b[0;32m~/.conda/envs/pmchhg/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1012\u001b[0m, in \u001b[0;36mTSNE._fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[39m# Degrees of freedom of the Student's t-distribution. The suggestion\u001b[39;00m\n\u001b[1;32m   1007\u001b[0m \u001b[39m# degrees_of_freedom = n_components - 1 comes from\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[39m# \"Learning a Parametric Embedding by Preserving Local Structure\"\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[39m# Laurens van der Maaten, 2009.\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m degrees_of_freedom \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m-> 1012\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tsne(\n\u001b[1;32m   1013\u001b[0m     P,\n\u001b[1;32m   1014\u001b[0m     degrees_of_freedom,\n\u001b[1;32m   1015\u001b[0m     n_samples,\n\u001b[1;32m   1016\u001b[0m     X_embedded\u001b[39m=\u001b[39;49mX_embedded,\n\u001b[1;32m   1017\u001b[0m     neighbors\u001b[39m=\u001b[39;49mneighbors_nn,\n\u001b[1;32m   1018\u001b[0m     skip_num_points\u001b[39m=\u001b[39;49mskip_num_points,\n\u001b[1;32m   1019\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/pmchhg/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:1064\u001b[0m, in \u001b[0;36mTSNE._tsne\u001b[0;34m(self, P, degrees_of_freedom, n_samples, X_embedded, neighbors, skip_num_points)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[39m# Learning schedule (part 1): do 250 iteration with lower momentum but\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39m# higher learning rate controlled via the early exaggeration parameter\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m P \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mearly_exaggeration\n\u001b[0;32m-> 1064\u001b[0m params, kl_divergence, it \u001b[39m=\u001b[39m _gradient_descent(obj_func, params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mopt_args)\n\u001b[1;32m   1065\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n\u001b[1;32m   1066\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m   1067\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m[t-SNE] KL divergence after \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m iterations with early exaggeration: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1068\u001b[0m         \u001b[39m%\u001b[39m (it \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, kl_divergence)\n\u001b[1;32m   1069\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/pmchhg/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:399\u001b[0m, in \u001b[0;36m_gradient_descent\u001b[0;34m(objective, p0, it, n_iter, n_iter_check, n_iter_without_progress, momentum, learning_rate, min_gain, min_grad_norm, verbose, args, kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39m# only compute the error when needed\u001b[39;00m\n\u001b[1;32m    397\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcompute_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m check_convergence \u001b[39mor\u001b[39;00m i \u001b[39m==\u001b[39m n_iter \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 399\u001b[0m error, grad \u001b[39m=\u001b[39m objective(p, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    401\u001b[0m inc \u001b[39m=\u001b[39m update \u001b[39m*\u001b[39m grad \u001b[39m<\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    402\u001b[0m dec \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39minvert(inc)\n",
      "File \u001b[0;32m~/.conda/envs/pmchhg/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:280\u001b[0m, in \u001b[0;36m_kl_divergence_bh\u001b[0;34m(params, P, degrees_of_freedom, n_samples, n_components, angle, skip_num_points, verbose, compute_error, num_threads)\u001b[0m\n\u001b[1;32m    277\u001b[0m indptr \u001b[39m=\u001b[39m P\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mint64, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    279\u001b[0m grad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(X_embedded\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m--> 280\u001b[0m error \u001b[39m=\u001b[39m _barnes_hut_tsne\u001b[39m.\u001b[39;49mgradient(\n\u001b[1;32m    281\u001b[0m     val_P,\n\u001b[1;32m    282\u001b[0m     X_embedded,\n\u001b[1;32m    283\u001b[0m     neighbors,\n\u001b[1;32m    284\u001b[0m     indptr,\n\u001b[1;32m    285\u001b[0m     grad,\n\u001b[1;32m    286\u001b[0m     angle,\n\u001b[1;32m    287\u001b[0m     n_components,\n\u001b[1;32m    288\u001b[0m     verbose,\n\u001b[1;32m    289\u001b[0m     dof\u001b[39m=\u001b[39;49mdegrees_of_freedom,\n\u001b[1;32m    290\u001b[0m     compute_error\u001b[39m=\u001b[39;49mcompute_error,\n\u001b[1;32m    291\u001b[0m     num_threads\u001b[39m=\u001b[39;49mnum_threads,\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    293\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m2.0\u001b[39m \u001b[39m*\u001b[39m (degrees_of_freedom \u001b[39m+\u001b[39m \u001b[39m1.0\u001b[39m) \u001b[39m/\u001b[39m degrees_of_freedom\n\u001b[1;32m    294\u001b[0m grad \u001b[39m=\u001b[39m grad\u001b[39m.\u001b[39mravel()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pca = PCA(10)\n",
    "pca_tranformed_features_cls = pca.fit_transform(features_cls)\n",
    "tsne = TSNE(perplexity=2, verbose=10, n_jobs=10)\n",
    "transformed_features_cls = tsne.fit_transform(pca_tranformed_features_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, term in enumerate(all_terms):\n",
    "    plt.scatter(*transformed_features_cls.T)\n",
    "    plt.text(transformed_features_cls.T[0][i], transformed_features_cls.T[1][i], term)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpat.mil.models.ccmil import CCMIL\n",
    "from dpat.mil.models.varmil import VarAttention\n",
    "from dpat.data import PMCHHGH5Dataset, PMCHHGH5DataModule\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dm = PMCHHGH5DataModule(\n",
    "    file_path=\"/home/sdejong/pmchhg/features/imagenet-11-4-2023-fold-0.hdf5\",\n",
    "    train_path=\"/home/sdejong/pmchhg/images-tif/splits_with_locations/medulloblastoma+pilocytic-astrocytoma_pmchhg_train-subfold-0-fold-0.csv\",\n",
    "    val_path=\"/home/sdejong/pmchhg/images-tif/splits_with_locations/medulloblastoma+pilocytic-astrocytoma_pmchhg_val-subfold-0-fold-0.csv\",\n",
    "    test_path=\"/home/sdejong/pmchhg/images-tif/splits_with_locations/medulloblastoma+pilocytic-astrocytoma_pmchhg_test-subfold-0-fold-0.csv\",\n",
    "    clinical_context=False,\n",
    "    num_classes=2,\n",
    ")\n",
    "dm.setup(\"fit\")\n",
    "\n",
    "ccmil = CCMIL(\n",
    "    in_features=1024,\n",
    "    layers=[2, 2, 2],\n",
    "    num_classes=2,\n",
    "    T_max=1000,\n",
    "    dropout=0.5,\n",
    "    lr= 0.0003,\n",
    "    momentum = 0.01,\n",
    "    wd = 0.01,\n",
    ").eval()\n",
    "\n",
    "varmil = VarAttention(\n",
    "    in_features=1024,\n",
    "    layers=[2, 2, 2],\n",
    "    num_classes=2,\n",
    "    T_max=1000,\n",
    "    dropout=0.5,\n",
    "    lr= 0.0003,\n",
    "    momentum = 0.01,\n",
    "    wd = 0.01,\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCMIL tensor([[-0.2352, -0.1425]])\n",
      "t= 2.5096795558929443\n",
      "VarMIL tensor([[-0.2796,  0.5978]])\n",
      "t= 0.807194709777832\n",
      "\n",
      "\n",
      "CCMIL tensor([[-0.2352, -0.1425]])\n",
      "t= 0.39732885360717773\n",
      "VarMIL tensor([[-0.2796,  0.5978]])\n",
      "t= 0.30567264556884766\n",
      "\n",
      "\n",
      "CCMIL tensor([[-0.2352, -0.1425]])\n",
      "t= 0.3991687297821045\n",
      "VarMIL tensor([[-0.2796,  0.5978]])\n",
      "t= 0.4811522960662842\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(loader))\n",
    "    for _ in range(3):\n",
    "        start = time()\n",
    "        print(\"CCMIL\", ccmil(batch[\"data\"], str(batch[\"cc\"]))[0])\n",
    "        print(\"t=\", time() - start)\n",
    "        start = time()\n",
    "        print(\"VarMIL\", varmil(batch[\"data\"])[0])\n",
    "        print(\"t=\", time() - start)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmchhg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
